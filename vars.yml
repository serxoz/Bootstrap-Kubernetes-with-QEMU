###############################################################################################
#                                      -General Options-                                      #
###############################################################################################
# These parameters are required.                                                              #
###############################################################################################

# qcow2 image to use for your Virtual Machines:
#qcow2_image: 'https://cdimage.debian.org/cdimage/openstack/current-10/debian-10-openstack-amd64.qcow2'
#qcow2_image: 'https://cdimage.debian.org/cdimage/openstack/current-10/debian-10.7.2-20201230-openstack-amd64.qcow2'
qcow2_image: 'https://cloud.debian.org/images/cloud/buster/daily/20210108-509/debian-10-generic-amd64-daily-20210108-509.qcow2'

# Location to use for storing the qcow2 image. Be sure to end the absolute path with a '/'.
qcow2_download_location: '/tmp/'

# Resource Pool for your virtual machines.
k8s_resource_pool: 'Kubernetes'

# Path to the SSH Public Key on your Proxmox Server.
k8s_ssh_key: '/root/.ssh/k8s-proxmox.pub'

# CIDR for the Calico Pod Network - MUST be different from your Kubernetes CIDR to avoid an IP conflict. Subnet size will automatically be set to /16.
calico_cidr: '172.16.0.0'

# URL for the Calico Network Policy:
# Can be found here: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#tabs-pod-install-2
calico_policy_url: 'https://docs.projectcalico.org/v3.14/manifests/calico.yaml'

# The version of Docker to use on the hosts.
# Make sure the version is listed here: https://kubernetes.io/docs/setup/release/notes/
# You can list available versions with: `aptitude versions docker-ce`
docker_version: '5:19.03.11~3-0~debian-buster'

# The version of Kubernetes to install.
# The newest release can be found here: https://kubernetes.io/docs/setup/release/notes/
#kubernetes_version: "v1.18.0"
kubernetes_version: "v1.20.0"

# VM IDs
k8s_master_id: '4010'
k8s_node1_id: '40100'
k8s_node2_id: '40101'
k8s_node3_id: '40102'

# Hostnames
k8s_master_hn: 'k8s-master'
k8s_node1_hn: 'k8s-node1'
k8s_node2_hn: 'k8s-node2'
k8s_node3_hn: 'k8s-node3'

# Number of CPUs
k8s_master_cpu: '2'
k8s_node1_cpu: '2'
k8s_node2_cpu: '2'
k8s_node3_cpu: '2'

# Amount of memory expressed in megabytes
k8s_master_mem: '2048'
k8s_node1_mem: '2048'
k8s_node2_mem: '2048'
k8s_node3_mem: '2048'

# Disk Sizes
k8s_master_size: '10G'
k8s_node1_size: '10G'
k8s_node2_size: '10G'
k8s_node3_size: '10G'

# IP Addresses
k8s_master_ip: '192.168.1.80'
k8s_node1_ip: '192.168.1.90'
k8s_node2_ip: '192.168.1.91'
k8s_node3_ip: '192.168.1.92'

# Subnet Sizes
k8s_master_sn: '/24'
k8s_node1_sn: '/24'
k8s_node2_sn: '/24'
k8s_node3_sn: '/24'

# Network Gateway
k8s_master_gw: '192.168.1.1'
k8s_node1_gw: '192.168.1.1'
k8s_node2_gw: '192.168.1.1'
k8s_node3_gw: '192.168.1.1'

# DNS Servers
k8s_master_ns: '192.168.1.2'
k8s_node1_ns: '192.168.1.2'
k8s_node2_ns: '192.168.1.2'
k8s_node3_ns: '192.168.1.2'

# Search Domains
k8s_master_sd: 'lan'
k8s_node1_sd: 'lan'
k8s_node2_sd: 'lan'
k8s_node3_sd: 'lan'

# Network Bridges
k8s_master_bridge: 'vmbr0'
k8s_node1_bridge: 'vmbr0'
k8s_node2_bridge: 'vmbr0'
k8s_node3_bridge: 'vmbr0'

# Storage volumes
k8s_master_stg: 'local-lvm'
k8s_node1_stg: 'local-lvm'
k8s_node2_stg: 'local-lvm'
k8s_node3_stg: 'local-lvm'


###############################################################################################
#                                     -Dashboard Options-                                     #
###############################################################################################
# These parameters are only required if you intend to deploy the Kubernetes Dashboard to your #
# cluster. If you wish to bind the Dashboard service to a Load Balanced IP Address, then      #
# uncomment and provide the values below. If you wish to deploy the Dashboard like normal,    #
# and use `kubectl-proxy` or `kubectl port-forward` to expose it, leave them commented out.   #
#                                                                                             #
# If you exposed the Dashboard with MetalLB, you can navigate to: https://HOSTNAME:8443/      #
# If you are exposing the Dashboard with `kubectl proxy`, you can find instructions on how to #
# access the dashboard here:                                                                  #
# https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/               #
#                                                                                             #
# TKS has already provisioned a Service Account that you can use to authenticate against your #
# Dashboard. You can retrieve this token like so. Be sure to replace K8S_USER_NAME with the   #
#value that you set for `k8s_user_name` above.                                                #
# kubectl describe -n kube-system secret K8S_USER_NAME-token | grep token: | awk '{print $2}' #
###############################################################################################

# The URL for the Kubernetes Dashboard Manifest. Not locally hosted as it changes frequently.
# Can be found here: https://github.com/kubernetes/dashboard/blob/master/README.md#getting-started
k8s_dashboard_url: 'https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml'

# Service user created for the dashboard.
k8s_user_name: 'sergio'

# The MetalLB Address Pool from which you want to obtain an IP address.
dashboard_load_balancer_address_pool: 'layer2'

# The IP address within the Address Pool to which you want to bind the service.
dashboard_load_balancer_ip: '192.168.1.70'

# The hostname with which you want to test connectivity to the IP Address after the deployment has completed.
dashboard_hostname: 'dash.lan'


###############################################################################################
#                                        -VLAN Options-                                       #
###############################################################################################
# These parameters are only required if your network is configured with VLANs and you wish to #
# specify which VLAN each of your Kubernetes nodes is allocated to. Leave these variables     #
# blank if you do not intend to use VLANs for your cluster.                                   #
###############################################################################################

# VLAN Tags
k8s_master_vlan: ''
k8s_node1_vlan: ''
k8s_node2_vlan: ''
k8s_node3_vlan: ''


###############################################################################################
#                                    -Unattended Upgrades-                                    #
#                                WARNING: EXPERIMENTAL FEATURE                                #
###############################################################################################
# These parameters are only required if you want to enable Unattended Upgrades on the         #
# operating systems that comprise your Kubernetes master and worker nodes. None of these      #
# variables are required to enable the feature. However, you may wish to enable email         #
# notifications via SMTP or tweak the way in which Unattended Upgrades are applied to your    #
# system. To do so, simply uncomment the relevant configuration setting.                      #
#                                                                                             #
# NOTE: If you enable any of the following variables, then you must enable the other ones as  #
# well or SMTP will not work:                                                                 #
#     - smtp_server                                                                           #
#     - smtp_port                                                                             #
#     - smtp_username                                                                         #
#     - smtp_password                                                                         #
#     - email_address                                                                         #
###############################################################################################

# SMTP Server
smtp_server: 'smtp.gmail.com'

# SMTP Port
smtp_port: '587'

# SMTP Server username
smtp_username: 'thomaszimmerman93@gmail.com'

# SMTP Server password
smtp_password: 'PASSWORD'

# The email address to which notifications will be delivered.
email_address: 'thomaszimmerman93@gmail.com'

# You want to be naughty and use SMTP without TLS.
#smtp_use_tls: 'off'

# Only receive emails when an error occurs.
# mail_only_on_error: "true"

# Only perform upgrades when a graceful OS shutdown occurs.
update_only_on_shutdown: "true"

# Automatically remove unused kernel packages.
# remove_unused_kernel_packages: "true"

# Automatically remove unused dependencies.
# remove_unused_dependencies: "true"

# Automatically perform a reboot after upgrading if required.
#automatic_reboot_if_required: "true"

# If automatic reboots are enabled, configure the time at which they occur.
#automatic_reboot_time: "02:00"

# Enable logging to syslog.
enable_syslog_logging: "true"


###############################################################################################
#                                        -NFS Options-                                        #
###############################################################################################
# These parameters are only required if you have an NFS server and would like to enable the   #
# optional support for dynamic provisioning of Persistent Storage volumes for your pods.      #
###############################################################################################

# NFS server
nfs_hostname: 'earth.sol.milkyway'

# NFS Mount Point
nfs_mount_point: '/mnt/DataPool/Kubernetes'

# NFS Provisioner Name
nfs_provisioner: 'datapool'

# Namespace to deploy the NFS Provisioner to.
nfs_namespace: 'nfs-provisioner'

# Default reclaim policy. https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy
nfs_reclaim_policy: 'Retain'


###############################################################################################
#                                      -MetalLB Options-                                      #
###############################################################################################
#                                                                                             #
# WARNING: MetalLB is currently supported, however dynamic provisioning is NOT currently      #
# supported despite the explanation below. This will come in a later release, however, if you #
# are interested in using this feature you will need to modify the configmap located in the   #
# MetalLB files directory yourself to match the variables you declare here.                   #
#                                                                                             #
# These parameters are only required if you want to enable on-prem load balancing with        #
# MetalLB. The MetalLB configuration file will be dynamically provisioned based on how many   #
# variable sets you declare below. This is intended to allow you to provision a single or     #
# multiple address pools depending on your personal network configuration. The configuration  #
# is dynamically generated based on how many sets of variables you list below. For example:   #
#                                                                                             #
# If you wish to deploy a single address pool, you would declare these three variables.       #
#                                                                                             #
# metallb_ap1_name: NAME                                                                      #
# metallb_ap1_protocol: PROTOCOL                                                              #
# metallb_ap1_cidr: CIDR                                                                      #
#                                                                                             #
#                                                                                             #
# However, if you wished to declare two address pools, you would include a second set of      #
# variables where the `ap1` portion of the variable name is incremeneted by one.              #
#                                                                                             #
# metallb_ap1_name: NAME                                                                      #
# metallb_ap2_name: NAME                                                                      #
# metallb_ap1_protocol: PROTOCOL                                                              #
# metallb_ap2_protocol: PROTOCOL                                                              #
# metallb_ap1_cidr: CIDR                                                                      #
# metallb_ap2_cidr: CIDR                                                                      #
###############################################################################################

# The IP Address of the router you wish to peer with.
metallb_peer_router: '192.168.1.1'

# The AS Number of the router you wish to peer with.
#metallb_peer_asn: '64512'
metallb_peer_asn: ''

# The names of your address pools.
metallb_ap1_name: 'LAN'
metallb_ap4_name: ''
metallb_ap2_name: ''
metallb_ap3_name: ''

# The protocols of your address pools. (bgp|layer2)
metallb_ap1_protocol: 'layer2'
metallb_ap2_protocol: ''
metallb_ap3_protocol: ''
metallb_ap4_protocol: ''

# The CIDRs of your address pools.
#metallb_ap1_cidr: '192.168.1.1/24'
metallb_ap1_cidr: '192.168.1.50-192.168.1.69'
metallb_ap2_cidr: ''
metallb_ap3_cidr: ''
metallb_ap4_cidr: ''


###############################################################################################
#                              -NGINX Ingress Controller Options-                             #
###############################################################################################
# These parameters are only required if you want to enable the NGINX ingress controller.      #
# REQUIREMENT: The NGINX Ingress controller integration requires a Load Balancer integration. #
###############################################################################################

# The IP Address to use
nginx_load_balancer_ip: '192.168.1.90'


###############################################################################################
#                                      -DataDog Options-                                      #
###############################################################################################
# These parameters are only required if you have an account with DataDog and would like to    #
# enable metrics collection for your cluster.                                                 #
###############################################################################################

# Your DataDog API Key
dd_api_key: 'APIKEY'

# Namespace to deploy DataDog to
dd_namespace: 'default'
